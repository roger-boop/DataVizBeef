---
title: "home-assignment"
author: "Oscar Casals, Roger Bosch, Albert Vidal"
date: "2022-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

For this project we will use three data frames containing the expression different genes have in certain cells after being exposed to some drugs in order to determine if there is a big disparity between the effects of each substance or instead they have near identical consequences.

To aid us in this task we have a file containing the metadata of each sample, in specific their cell type and the drug it has been subjected to.

The tools we will use to visualise our data are: PCA(principal component analysis), tSNE(t-Distributed Stochastic Neighbor Embedding) and UMAP(Uniform Manifold Approximation and Projection).
 
With all the materials defined let's get going with the analysis.

## Q1

**Load the data from the three plates. Which command do you use? Provide code alternatives and prove that the data is loaded.**

Our first step in this analysis is to load the data contained in the tsv files, an easy way to perform this task is with a simple `read.table()`.

```{r q1-loads, error=TRUE}
P3 <- read.table('P3.tsv', header = TRUE)
P4 <- read.table('P4.tsv', header = TRUE)
P5 <- read.table('P5.tsv', header = TRUE)
```

This method but has the inconvenience of requiring to decompress the data, which might not be a good idea when working with large files, that is why we will use the `gzfile()` function to avoid this problem.

```{r q1-loads-alt, error=TRUE}
P3_2 <- read.table(gzfile("P3.tsv.gz"), header = TRUE)
P4_2 <- read.table(gzfile("P4.tsv.gz"), header = TRUE)
P5_2 <- read.table(gzfile("P5.tsv.gz"), header = TRUE)
```

While read.table is the standard to import any table into r, there are some other functions we can use to import tsv files:

  - We could use `read_tsv()`, a function specialized in loading tsv files into R.

```{r q1-loads-alt2, error=TRUE}
library(readr)
P3_3 <- read_tsv(gzfile("P3.tsv.gz"), col_names = TRUE)
P4_3 <- read_tsv(gzfile("P4.tsv.gz"), col_names = TRUE)
P5_3 <- read_tsv(gzfile("P5.tsv.gz"), col_names = TRUE)
```

  - We could also treat our data like a csv file and load it into R using `read_csv()`. In this case we must specify that each column is separated by a tab in order to prevent the function of returning a table with just one column.

```{r, error=TRUE}
P3_4 <- read.csv(gzfile("P3.tsv.gz"), header = TRUE, sep = "\t")
P4_4 <- read.csv(gzfile("P4.tsv.gz"), header = TRUE, sep = "\t")
P5_4 <- read.csv(gzfile("P5.tsv.gz"), header = TRUE, sep = "\t")
```

  - Finally we can take advantage of the fact that tsv files are delimited text files to load our data using `read.delim()`.

```{r, error=TRUE}
P3_5 <- read.delim(gzfile("P3.tsv.gz"), header = TRUE)
P4_5 <- read.delim(gzfile("P4.tsv.gz"), header = TRUE)
P5_5 <- read.delim(gzfile("P5.tsv.gz"), header = TRUE)
```

Now we will check that the data has been loaded as expected using `head()`, a function that prints the first few lines of the data frame it receives as input. Since we are testing all the methods used to load the data showing the output of the following chunk would fill the html with non-relevant information, that is why you will have to trust us when we say the code worked as expected or replicate what we have done until now to test it.

```{r q1-evidence, error=TRUE, results='hide'}
#Data loaded with read.table
head(P3)
head(P4)
head(P5)
#Data loaded with read_tsv
head(P3_3)
head(P4_3)
head(P5_3)
#Data loaded with read.csv
head(P3_4)
head(P4_4)
head(P5_4)
#Data loaded with read.delim
head(P3_5)
head(P4_5)
head(P5_5)
```

Right now our tables have the name of the genes as row names and the sample names as colnames, this makes our data unintuitive to navegate so we will set the gene column as rownames, remove it since it is no longer necessary, and transpose the tables so everything looks as we want to. 


```{r q1-transpose_matrix}
rownames(P3) <- P3$gene
P3$gene <- NULL
rownames(P4) <- P4$gene
P4$gene <- NULL
rownames(P5) <- P5$gene
P5$gene <- NULL

P3 <- t(P3)
P4 <- t(P4)
P5 <- t(P5)
```

## Q2

**Load the treatment associated with every cell. Which command do you use? How many different conditions are present in the plates? How many cells in each condition? Do you need to reorder cells so that data in sample sheet and tsv files match?**

The treatment associated to each cell can be found in the samplesheet.tsv, to load it we can use the `read.table()` command again.

```{r q2-packages, message=FALSE}
library(dplyr)
library(tidyr)
```

```{r q2-load}
treatments <- read.table('samplesheet.tsv', header = TRUE)
```

The table loaded contains cell types and conditions inside the column label, this is too much information for just a column so we will separate both features using the functions %>% and separate from the packages dplyr and tidyr respectively.

```{r q2-separate}
treatments <- treatments %>% separate(col = label, into = c("celltypes", "conditions"), sep = "\\+")
```

With the conditions separated from celltypes we can easily check how many we have using the table function, which creates a table containing the number of times a condition appears in treatments.

```{r q2-cond}
table(treatments$conditions)
```

**Thanks to the table above we know there are 3 different conditions present in the plates.**

**The same table can be used to know how many cells are present in each condition.**

```{r q2-cellconds}
table(treatments$conditions, treatments$celltypes)
```

Finally we need to figure out if we need to record cell names or not by checking if the indexes for each cell are the same in all the dataframes created. If they do, then we can remove them since we will already know which cell each column is referring to by binding the metadata with the tsv files, otherwise we will have to record it.

Our way of knowing wether the indexes align in all dataframes or not is by looking for false values in a condition that compares the rownames of P3, P4 and P5 with the cellnames present in treatment.


```{r q3-record_cell_or_not, echo=T}
table(treatments$cellnames == cbind(rownames(P3), rownames(P4), rownames(P5)))
```

**As we can see no False boolean appears which means all the indexes are identical and therefore, there is no need to record the cell names.**

Taking advantatge of the fact we are working with the treatments dataframe we are going to add a new column that contains the plate from which each cell comes from. Eventhough this new feature might seem useless right now it will be of use later when we check if there is batch effect or not.

To create this new column we used rep to generate the vectors that will conform the new feature and append to put it all together and add the new column to the dataframe.

```{r bind}
treatments$replicates <- append(append(rep("P3", 96), rep("P4",96)), rep("P5", 96))
```

We can see the index of the cells is the same in both treatments and the tsv files, therefore we don't have to record those names.

To end this exercise we will create a data frame with all the information obtained till now.

```{r final_data}
X <- rbind(P3, P4, P5)
```

## Q3

**Represent the data with a PCA projection and tSNE. Scale and normalize the data appropriately, showing the different steps in the process and compare with the raw data. Using colors, argue whether batch effects are present between the three plates. Provide different visualizations and/or code alternatives.**

This is a function that takes a dataframe and returns the same dataframe but scaled. This is done by first removing the columns with all zeroes, and later dividing all the observations by the sum of their row.

```{r scale-func}
my.normalize <- function(X)
{
  X_nozero <- X[, colSums(X)>0]
  return(X_nozero/rowSums(X_nozero))
}
```

Now that we have the function, let's normalize our dataset.

```{r scaling}
Y = my.normalize(X)
```

We will do two PCAs, first with the raw dataset and then with the scaled, normalized dataset. This is done so we can see if the batch effect is removed.

```{r first-pca}
pca <- stats::prcomp(X)
pca_normalized <- stats::prcomp(Y, scale = TRUE)
```

```{r libraries}
library(ggplot2)
library(Rtsne)
library(factoextra)
```

This is a function that takes the output of a PCA and automatically re-formats so it's easy to plot with ggplot.

```{r pca-components-make}
make_components <- function(pca)
{
  return (as_tibble(pca$x) %>% bind_cols(treatments) %>% as.data.frame())
}
```

We have everything ready, so let's plot the raw data PCA.

```{r pca-plot-no-normalized}
components <- make_components(pca)
ggplot(components, aes(x = PC1, y = PC2, color = replicates)) + geom_point() + theme_light() + labs(color = "Replicate", title = "PCA non-normalized")
```

There is a clear batch effect, mostly among the P3 replicate, as they are mostly clustered away from the P4 and P5 clusters. Let's plot the normalized PCA.

```{r pca-plot-normalized}
components <- make_components(pca_normalized)
ggplot(components, aes(x = PC1, y = PC2, color = replicates)) + geom_point() + theme_light() + labs(color = "Replicates", title = "PCA normalized")
```

This might have solved the batch effect, but there is 1 huge outlier along the PC1 in our data. Let's remove it.

First, let's see the name of the outlier sample so we can remove it. We can re-do the plot with the names.

```{r outlier-plot}
fviz_pca_ind(pca_normalized, repel = T)
```

We must remove P2771_N704.S506 from our dataset.

```{r remove-outlier, results='hide'}
X <- X[! rownames(X) %in% 'P2771_N704.S506',]
treatments <- treatments %>% filter(!cellnames %in% 'P2771_N704.S506')
Y <- my.normalize(X)
```

Now that the dataset has the outlier removed, let's plot once again.

```{r pca-normalized-no-outlier}
pca_normalized <- stats::prcomp(Y, scale = TRUE)
components <- make_components(pca_normalized)
ggplot(components, aes(x = PC1, y = PC2, color = replicates)) + geom_point() + theme_light() + labs(color = "Replicates", title = "PCA normalized")
```

The outlier is gone, and we can clearly differentiate the clusters. The batch effect is also clearly gone compared to the non-scaled, non-normalized PCA. Let's do some tSNEs, both for the raw and normalized data.

```{r tsnes}
X_tsne <- Rtsne(X)
Y_tsne <- Rtsne(Y)
```

Let's make a function that automatically modifies our data to make an easy input to ggplot. It only takes one argument - the tSNE we want to plot - and it does the rest automatically.

```{r tsne-func}
make_tsne_plot <- function(tsne)
{
  tsne_plot <- data.frame(x = tsne$Y[,1], 
                        y = tsne$Y[,2], 
                        col = treatments$replicates,
                        sha = treatments$conditions,
                        alp = treatments$celltypes)
  return(tsne_plot)
}
```

tSNE is a heuristic algorithm, which means that it will return a different plot every time we execute it. So, let's fix a seed so we can have reproducible results.

```{r seed}
set.seed(123)
```

Let's plot the raw data.

```{r tsne-non-normalized}
tsne_plot <- make_tsne_plot(X_tsne)
ggplot(tsne_plot) + geom_point(aes(x=x, y=y, color=col)) + theme_light() + labs(color = "Replicates", title = "tSNE non-normalized")
```

There is some clear batch effect once again. Let's remove it by plotting the normalized data.

```{r tsne-normalized}
tsne_plot <- make_tsne_plot(Y_tsne)
ggplot(tsne_plot) + geom_point(aes(x=x, y=y, color=col)) + theme_light() + labs(color = "Replicates", title = "tSNE normalized") 
```

We had already removed the outlier in the PCA step so we have nothing extra to do.
TODO: DISCUSS

## Q4

**Check the effect of perplexity and iterations, the same as scaling the data for tSNE and PCA plots respectively.**

Let's try to change the perplexity parameter and see how it affects the data.

```{r perplex}
for (i in c(3, 60, 70))
{
  i_tsne <- Rtsne(Y, perplexity = i)
  tsne_plot <- make_tsne_plot(i_tsne)
  print(ggplot(tsne_plot) + geom_point(aes(x=x, y=y, color=col)) + theme_light() + labs(color = "Replicates", title = paste0("tSNE for perplexity = ", i)))
}
```

The perplexity changes the number of neighbors that each cluster should have. For perplexity = 3, the clusters only have 3 neighbors, so the clusters are tiny. It's good to have a high perplexity, as high as possible. 

Let's try changing the iterations now.

```{r iter}
for (i in c(5, 500, 2000))
{
  i_tsne <- Rtsne(Y, max_iter = i)
  tsne_plot <- make_tsne_plot(i_tsne)
  print(ggplot(tsne_plot) + geom_point(aes(x=x, y=y, color=col)) + theme_light() + labs(color = "Replicates", title = paste0("tSNE for iterations = ", i)))
}
```

A lower number of iterations leads to one singular big cluster. The more iterations, the more distinct the clusters are. A higher number is better in this case.

## Q5

**Argue whether the drugs SAHA and PMA have the same effect on the cells. Add a legend and label the axes accordingly.**

In order to determine whether or not SAHA and PMA have the same effect on the cells, we will perform a PCA and see if those two drugs share a cluster.

```{r totalexpr-func}
totalExpr <- function(X)
{
  X_nozero <- X[, colSums(X)>0]
  return (rowSums(X_nozero))
}
```

```{r}
X_SAHA_PMA <- X[((treatments$conditions == "SAHA") == TRUE) | ((treatments$conditions == "PMA")== TRUE),]

treat_SAHA_PMA <- treatments[(treatments$conditions == "SAHA") | (treatments$conditions == "PMA"),]

Y_SAHA_PMA <- my.normalize(X_SAHA_PMA)

PCA_filtered <- stats::prcomp(Y_SAHA_PMA, scale = TRUE)

components_filtered <- components[(components$conditions == "SAHA") | (components$conditions == "PMA"),]

ggplot(components_filtered, aes(x = PC1, y = PC2, color = conditions, shape = celltypes)) + geom_point() + theme_light() + scale_shape_manual(values = c(3,17)) +  labs(color = "Conditions", shape = "Cell type")

```

In the plot above we can see that PMA and SAHA do not have the same effect on cells since they do not share a cluster. The clusters contain cells of both types.

## Q6

**Using the correct PCA analysis, find an interpretation for the first and the second principal component.**

```{r}
pl <- ggplot(components, aes(x = PC1, y = PC2, color = totalExpr(X), shape = conditions)) + geom_point() + scale_colour_gradient(low = "#00FF00", high = "#FF0000") + scale_shape_manual(values = c(3,17, 11)) + theme_light() + labs(color = "Expression", shape = "Conditions", title = "PCA")

pl
```

PC2 seems to separate cells based on their conditions while PC1 based on their total expression. 

## Q7

**Using your answer to the previous question, find three genes that are activated by SAHA but not by PMA.**

In order to do this, we will subset all cells with SAHA and PMA respectively and sum all the expressions of their genes. This is not the total expression of the cell, but the total expression of each gene. Then, we take the 3 most expressed genes in SAHA and the 3 most expressed genes in PMA, and compare them.

```{r}
SAHA_cells <- treatments %>% filter(conditions == "SAHA") %>% pull(cellnames)
PMA_cells <- treatments %>% filter(conditions == "PMA") %>% pull(cellnames)
SAHA_Y <- Y[SAHA_cells,]
PMA_Y <- Y[PMA_cells,]

names(colSums(SAHA_Y)[order(colSums(SAHA_Y), decreasing=TRUE)[1:3]])
names(colSums(PMA_Y)[order(colSums(PMA_Y), decreasing=TRUE)[1:3]])
```

After this procedure we see that the 3 most expressed genes in SAHA are not the same as in PMA. Therefore, we can claim that 


ENSG00000251562.8  ENSG00000198804.2  ENSG00000280614.1


Are activated by SAHA but not by PMA.






## Q8

**Create a UMAP visualization of the results. Explore differences between producing**
**results from raw data counts or normalized results. Explore also the effect of predicting**
**a new sample result from previous UMAP analysis. Compare results and give some**
**thoughts on it.**

```{r libraries-2}
library(umap)
```

To make the procedure easier, we have made a function that automatically takes a UMAP analysis and re-formats it so it can work well with ggplot.

```{r umap-func}
make_umap_data <- function(UMAP)
{
  return( data.frame(x = UMAP$layout[,1], y = UMAP$layout[,2], col = treatments) )
}
```

Let's do both UMAPs, for normalized and non-normalized data, and compare them.

```{r umap-1}
UMAP_X <- umap::umap(X)
UMAP_Y <- umap::umap(Y)
UMAP_data_X <- make_umap_data(UMAP_X)
UMAP_data_Y <- make_umap_data(UMAP_Y)
ggplot(UMAP_data_X, aes(x = x, y = y, shape = col.conditions, color=col.replicates)) + geom_point() + scale_shape_manual(values = c(3,17, 11)) + theme_light() + labs(color = "Expression", shape = "Conditions", title = "Non-scaled UMAP")
ggplot(UMAP_data_Y, aes(x = x, y = y, shape = col.conditions, color=col.replicates)) + geom_point() + scale_shape_manual(values = c(3,17, 11)) + theme_light() + labs(color = "Expression", shape = "Conditions", title = "Normalized UMAP")
```

DISCUSS DIFFERENCES OF NORMALIZED/NON NORMALIZED

Now that we have done that, we can recreate the other plots we performed but with UMAP and see if the results match.

```{r umap-2}
ggplot(UMAP_data_Y, aes(x = x, y = y, shape = col.conditions, color=totalExpr(X))) + geom_point() + 
  scale_colour_gradient(low = "#00FF00", high = "#FF0000") + scale_shape_manual(values = c(3,17, 11)) + theme_light() + 
  labs(color = "Expression", shape = "Conditions", title = "Normalized UMAP")
```

While the clusters are distributed differently, the clusters themselves are the same. There are SAHA, PMA and DMSO clusters all the same, like in the other plots we had done.

Next, let's make some predictions with UMAP. We will re-do the plot above but with all predicted data, using the UMAP model we used on the dataset Y.

```{r umap-predictions}
UMAP_predicted = stats::predict(UMAP_Y, Y)
UMAP_predicted_data <- data.frame(x = UMAP_predicted[,1], y = UMAP_predicted[,2], col = treatments)
ggplot(UMAP_predicted_data, aes(x = x, y = y, shape = col.conditions, color=totalExpr(X))) + geom_point() + 
  scale_colour_gradient(low = "#00FF00", high = "#FF0000") + scale_shape_manual(values = c(3,17, 11)) + theme_light() + 
  labs(color = "Expression", shape = "Conditions", title = "Normalized UMAP")
```

We can see that both plots are remarkably similar, with some minor differences, but the clusters remain the same.
(INTERPRETAR)

## Q9

**Test some parameters such as minimum distance and number of neighbors. Compare**
**results and give some thoughts on it.**

Let's begin by changing the minimum distance.

```{r umap-min-dist}
for (i in c(0.1,0.5,0.9))
{
  tmp.config <- umap::umap.defaults
  tmp.config$min_dist <- i
    
  UMAP_tmp <- umap::umap(Y, config = tmp.config)
  UMAP_data_tmp <- make_umap_data(UMAP_tmp)
  print(ggplot(UMAP_data_tmp, aes(x = x, y = y, shape = col.conditions, color=col.replicates)) + geom_point() + scale_shape_manual(values = c(3,17, 11)) +
          theme_light() + labs(color = "Expression", shape = "Conditions", title = paste0("UMAP with minimum distance = ", i)))
  
}
```

As we can see, the minimum distance determines how "tight" the clusters are. A small value leads to very compact, distinct clusters, and a large value leads to very "sparse" clusters. Note that, as per the default values for UMAP, the minimum distance must go from 0 to 1 (excluding those values). 

Now, let's see the effect of the number of neighbors.

```{r umap-neighbors, warning=FALSE}
for (i in c(2,10,50))
{
  tmp.config <- umap::umap.defaults
  tmp.config$n_neighbors <- i
    
  UMAP_tmp <- umap::umap(Y, config = tmp.config)
  UMAP_data_tmp <- make_umap_data(UMAP_tmp)
  print(ggplot(UMAP_data_tmp, aes(x = x, y = y, shape = col.conditions, color=col.replicates)) + geom_point() + scale_shape_manual(values = c(3,17, 11)) +
          theme_light() + labs(color = "Expression", shape = "Conditions", title = paste0("UMAP with num. neighbors = ", i)))
  
}
```

This variable determines the maximum number of neighbors each point can have. Notice that, for n_neighbors = 2, each point is perfectly paired with another. Note that the number of neighbors must be equal to or smaller than the number of samples. This makes sense, because you can't have more neighbors than there are points in the graph.

## Q10

**Create a final visualization using results from PCA, tSNE and UMAP and write some thoughts**
**on the comparison of the three high-dimension techniques.**
**Use as many metadata available as possible and generate clear and easy to interpret plots.**

Let's do 3 final plots. A PCA, a t-SNE and a UMAP. Later, we will discuss them.

```{r pca-final, warning=FALSE}
components <- make_components(pca_normalized)
ggplot(components, aes(x = PC1, y = PC2, color = totalExpr(X), shape = conditions, alpha = celltypes)) + geom_point() + scale_shape_manual(values = c(3,17, 11)) + scale_colour_gradient(low = "#00FF00", high = "#FF0000") + theme_light() + labs(color = "Total Expression", alpha = "Cell types", shape = "Conditions", title = "PCA")
```

```{r tsne-final, warning=FALSE}
tsne_plot <- make_tsne_plot(Y_tsne)
ggplot(tsne_plot) + geom_point(aes(x = x, y = y, color = totalExpr(X), shape = sha, alpha = alp)) + scale_shape_manual(values = c(3,17, 11)) + scale_colour_gradient(low = "#00FF00", high = "#FF0000") + theme_light() + labs(color = "Total Expression", alpha = "Cell types", shape = "Conditions", title = "tSNE")
```

```{r umap-final, warning=FALSE}
UMAP_data_Y <- make_umap_data(UMAP_Y)
ggplot(UMAP_data_Y, aes(x = x, y = y, shape = col.conditions, color=totalExpr(X), alpha = col.celltypes)) + geom_point() + 
  scale_colour_gradient(low = "#00FF00", high = "#FF0000") + scale_shape_manual(values = c(3,17, 11)) + theme_light() + 
  labs(color = "Expression", shape = "Conditions", title = "UMAP")
```

DISCUSS
